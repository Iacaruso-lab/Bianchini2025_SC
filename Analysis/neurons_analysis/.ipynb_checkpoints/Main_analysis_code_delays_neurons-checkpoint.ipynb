{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b3e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevants paths and load functions and libraries\n",
    "\n",
    "%run Bianchini2025_SC\\\\Analysis\\\\helper_functions\\\\functions_analysis.py\n",
    "    \n",
    "data_path = 'Bianchini2025_SC\\\\Datasets\\\\' # your data path\n",
    "saving_path = 'Bianchini2025_SC\\\\Figures_output\\\\' # your saving figures path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da88a5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AP_lim', 'ML_lim', 'all_boot_aud', 'all_boot_vis', 'animal_ID', 'binSize', 'coord3D', 'depth_lim', 'experiment_ID', 'modality', 'peaks', 'pvals', 'resp', 'spikes', 'trials', 'window_spikes'])\n"
     ]
    }
   ],
   "source": [
    "# import relevant datasets\n",
    "\n",
    "# load the main dataset\n",
    "file= ''.join([data_path,'neurons_datasets\\\\delay_tuning_dataset.mat'])\n",
    "data_dict = mat73.loadmat(file)\n",
    "DAT=data_dict['merged_dataset']\n",
    "\n",
    "# check keys available\n",
    "print(DAT.keys())\n",
    "\n",
    "# extract all keys\n",
    "for k in DAT.keys():\n",
    "    globals()[k] = DAT[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d033b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the onset of visual and audiotry responses - for this we use a 1ms binning\n",
    "\n",
    "file=''.join([data_path,'neurons_datasets\\\\all_spikes_1ms.mat'])\n",
    "data_dict = mat73.loadmat(file)\n",
    "DAT=data_dict['all_spikes']\n",
    "spikes_1ms = DAT['spikes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9a010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the onset of visual and audiotry responses\n",
    "# 1 - Define the standard deviation for the Gaussian filter\n",
    "sigma = 1.5\n",
    "spikes_1ms = spikes_1ms.astype(float)\n",
    "# Apply the Gaussian filter along the third axis\n",
    "spikes_smooth = gaussian_filter1d(spikes_1ms, sigma, axis=2) #axis 2 is time\n",
    "\n",
    "# Reshape the array to facilitate mean calculation\n",
    "reshaped_array= spikes_smooth.reshape(spikes_smooth.shape[0], -1, 50, spikes_smooth.shape[2])\n",
    "\n",
    "# Compute the mean along the second axis\n",
    "mean_array = np.mean(reshaped_array, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0334e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- extract peak time FR for vis and aud trials\n",
    "spikes_1ms.shape #window=[-1 1];\n",
    "latencies = np.zeros((spikes_smooth.shape[0],3))\n",
    "start_window = 5#ms\n",
    "start_window += 33#ms\n",
    "cut_array = mean_array[:,:,start_window:]\n",
    "\n",
    "for i in range(spikes_smooth.shape[0]): #for each neuron\n",
    "    latencies[i,0] = np.argmax(cut_array[i,-2,5:]) #vis latency\n",
    "    latencies[i,1] =  np.argmax(cut_array[i,-1,5:]) #aud latency\n",
    "    latencies[i,2] =  np.argmax(cut_array[i,0,5:]) #multi 0 latency\n",
    "    \n",
    "# Save the latencies for them to be easier to load for figure plotting\n",
    "\n",
    "save_dir = ''.join([data_path,'neurons_datasets\\\\latencies_vis_aud.npy'])\n",
    "np.save(save_dir,latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ac94f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate inter trial variaility for delay neurons\n",
    "\n",
    "# get the delay neurons\n",
    "peaks = np.squeeze(peaks)\n",
    "\n",
    "sig_del = []\n",
    "for i in range(peaks.shape[0]):\n",
    "    y = peaks[i,:-2]\n",
    "\n",
    "    vis_FR = peaks[i,-2]\n",
    "    aud_FR = peaks[i,-1]\n",
    "\n",
    "    if vis_FR>aud_FR:\n",
    "        boot_out = all_boot_vis[i,:]\n",
    "    elif aud_FR>vis_FR:\n",
    "        boot_out = all_boot_aud[i,:]\n",
    "    \n",
    "    pos_sig = np.argwhere(boot_out>0)\n",
    "\n",
    "    if len(pos_sig)>0:\n",
    "        sig_del.append(i)\n",
    "\n",
    "sig_del = np.array(sig_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb464914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this we use 10ms binning\n",
    "\n",
    "reshaped_array= spikes.reshape(spikes.shape[0], -1, 50, spikes.shape[2])\n",
    "reshaped_array = reshaped_array[:,:,:,98:98+25] # from -20ms to 250ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "933017af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 1/5360 [00:36<53:43:25, 36.09s/it]C:\\Users\\bianchg\\Miniconda3\\envs\\master\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4427: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "  4%|███▎                                                                         | 227/5360 [05:26<2:03:07,  1.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2\\ipykernel_15488\\3804042355.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[1;31m# Compute Pearson correlation coefficient between repeats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mcorrelation_coefficients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_neuron_spikes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthis_neuron_spikes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Loop through each trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\master\\lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36mpearsonr\u001b[1;34m(x, y, alternative)\u001b[0m\n\u001b[0;32m   4447\u001b[0m     \u001b[1;31m# use at least 64 bit floating point.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4448\u001b[0m     \u001b[0mxm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mxmean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4449\u001b[1;33m     \u001b[0mym\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mymean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4451\u001b[0m     \u001b[1;31m# Unlike np.linalg.norm or the expression sqrt((xm*xm).sum()),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get the shape of the reshaped array\n",
    "n_neurons, trials, reps, time_points = reshaped_array.shape\n",
    "\n",
    "# Initialize the final correlation array\n",
    "final_corr = np.zeros((n_neurons, trials))\n",
    "\n",
    "# Loop over neurons\n",
    "for n in tqdm(range(n_neurons)):\n",
    "    this_neuron_spikes = reshaped_array[n]\n",
    "\n",
    "    # Initialize an array to store correlation coefficients for each trial\n",
    "    correlation_coefficients = np.zeros((trials, reps, reps))\n",
    "\n",
    "    # Compute correlation coefficients for each trial\n",
    "    for trial in range(trials):\n",
    "        for i in range(reps):\n",
    "            for j in range(reps):\n",
    "                # Compute Pearson correlation coefficient between repeats\n",
    "                correlation_coefficients[trial, i, j],pval = pearsonr(this_neuron_spikes[trial, i], this_neuron_spikes[trial, j])\n",
    "\n",
    "    # Loop through each trial\n",
    "    for trial in range(trials):\n",
    "        # Extract the lower triangle of the correlation matrix\n",
    "        lower_triangle = np.tril(correlation_coefficients[trial,:,:])\n",
    "\n",
    "        # Exclude the main diagonal (i.e., correlation of a repeat with itself)\n",
    "        lower_triangle = lower_triangle[lower_triangle != 0]\n",
    "\n",
    "        # Calculate the average correlation coefficient for the trial\n",
    "        final_corr[n,trial] = np.nanmean(lower_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daa089d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_corr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2\\ipykernel_13256\\3491206831.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msave_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'neurons_datasets\\\\Inter_trial_variability_neurons.npy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_corr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'final_corr' is not defined"
     ]
    }
   ],
   "source": [
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "\n",
    "save_dir = ''.join([data_path,'neurons_datasets\\\\Inter_trial_variability_neurons.npy'])\n",
    "np.save(save_dir,final_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the chance reliability gets also calculated bu for the whole spike trains (larger window of time)\n",
    "\n",
    "file=''.join([data_path,'neurons_datasets\\\\all_spikes_large_window.mat'])\n",
    "data_dict = mat73.loadmat(file)\n",
    "DAT=data_dict['all_spikes']\n",
    "spikes_1ms = DAT['spikes']\n",
    "\n",
    "# for all possible times of 250ms length - to match the previous one\n",
    "reshaped_array2= spikes_10ms.reshape(spikes_10ms.shape[0], spikes_10ms.shape[1], 25,-1)\n",
    "reshaped_array2 = reshaped_array2.swapaxes(3,2)\n",
    "reshaped_array2 = reshaped_array2.reshape(reshaped_array2.shape[0],-1,reshaped_array2.shape[3])\n",
    "print(reshaped_array2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5297a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the reshaped array\n",
    "n_neurons, trials, reps, time_points = reshaped_array.shape\n",
    "\n",
    "# Initialize the final correlation array\n",
    "final_corr = np.zeros((n_neurons, trials))\n",
    "\n",
    "# Loop over neurons\n",
    "for n in tqdm(range(n_neurons)):\n",
    "    this_neuron_spikes = reshaped_array[n]\n",
    "\n",
    "    # Initialize an array to store correlation coefficients for each trial\n",
    "    correlation_coefficients = np.zeros((trials, reps, reps))\n",
    "\n",
    "    # Compute correlation coefficients for each trial\n",
    "    for trial in range(trials):\n",
    "        for i in range(reps):\n",
    "            for j in range(reps):\n",
    "                # Compute Pearson correlation coefficient between repeats\n",
    "                correlation_coefficients[trial, i, j],pval = pearsonr(this_neuron_spikes[trial, i], this_neuron_spikes[trial, j])\n",
    "\n",
    "    # Loop through each trial\n",
    "    for trial in range(trials):\n",
    "        # Extract the lower triangle of the correlation matrix\n",
    "        lower_triangle = np.tril(correlation_coefficients[trial,:,:])\n",
    "\n",
    "        # Exclude the main diagonal (i.e., correlation of a repeat with itself)\n",
    "        lower_triangle = lower_triangle[lower_triangle != 0]\n",
    "\n",
    "        # Calculate the average correlation coefficient for the trial\n",
    "        final_corr[n,trial] = np.nanmean(lower_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5330d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and it get saved so it is easier for th eplotting ot just load it\n",
    "\n",
    "save_dir = ''.join([data_path,'neurons_datasets\\\\Inter_trial_variability_neurons_random.npy'])\n",
    "np.save(save_dir,final_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed0626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data for density map of visual, auditory and multisensory neruons across regions of the SC (Supp. Fig 1C)\n",
    "# load the atlas SC images\n",
    "\n",
    "dir1=file=''.join([data_path,'SC_AP_modified.tif'])\n",
    "im_AP = imageio.imread(dir1)\n",
    "img = Image.open(dir1)\n",
    "\n",
    "dir2=file=''.join([data_path,'SC_ML_modified.tif'])\n",
    "im_ML = imageio.imread(dir2)\n",
    "\n",
    "im_AP=img.resize((im_AP.shape[0],im_ML.shape[0]))\n",
    "\n",
    "#normalize values\n",
    "ML_norm = ((coord3D[:,2] - ML_lim[0]) / (ML_lim[1] - ML_lim[0]))*im_ML.shape[1]\n",
    "AP_norm = ((coord3D[:,0] - AP_lim[0]) / (AP_lim[1] - AP_lim[0]))*(673)+20\n",
    "depth_norm = ((coord3D[:,1] -depth_lim[0]) / (depth_lim[1] - depth_lim[0]))*im_ML.shape[0]\n",
    "\n",
    "ML_norm2 = ((coord3D[:,2] - ML_lim[0]) / (ML_lim[1] - ML_lim[0]))\n",
    "AP_norm2 = ((coord3D[:,0] - AP_lim[0]) / (AP_lim[1] - AP_lim[0]))\n",
    "depth_norm2 =  ((coord3D[:,1] -depth_lim[0]) / (depth_lim[1] - depth_lim[0]))\n",
    "\n",
    "ML_norm3 = coord3D[:,2] - ML_lim[0]\n",
    "AP_norm3 = coord3D[:,0] - AP_lim[0]\n",
    "depth_norm3 = coord3D[:,1] - depth_lim[0]\n",
    "\n",
    "coord3D_norm= np.transpose(np.array([ML_norm,AP_norm,depth_norm]))\n",
    "coord3D_norm2= np.transpose(np.array([ML_norm2,AP_norm2,depth_norm2]))\n",
    "\n",
    "# invert the ML axis first\n",
    "\n",
    "max_val = im_ML.shape[1]\n",
    "min_val = 0 \n",
    "new_ML = np.array([max_val - val + min_val for val in ML_norm])\n",
    "ML_norm = new_ML\n",
    "\n",
    "max_val = 1\n",
    "min_val = 0 \n",
    "new_ML = np.array([max_val - val + min_val for val in ML_norm2])\n",
    "ML_norm2 = new_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f342a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% get the proportion of neurons for spatial bin and save it to plot it in Supplementary Figure 2\n",
    "\n",
    "good_pos2 = np.argwhere(~np.isnan(AP_norm))\n",
    "extremes = np.array([0,(673)+20])\n",
    "AP_corr = np.concatenate([np.squeeze(AP_norm[good_pos2]),extremes])\n",
    "\n",
    "extremes = np.array([0,im_ML.shape[1]])\n",
    "ML_corr = np.concatenate([np.squeeze(ML_norm[good_pos2]),extremes])\n",
    "\n",
    "extremes = np.array([0,im_ML.shape[0]])\n",
    "depth_corr = np.concatenate([np.squeeze(depth_norm[good_pos2]),extremes])\n",
    "\n",
    "experiment_ID_corr = experiment_ID[good_pos2]\n",
    "animal_ID_corr = animal_ID[good_pos2]\n",
    "\n",
    "modality_corr = modality[good_pos2]\n",
    "\n",
    "n_bins_tot=20\n",
    "id_AP,edges_AP  = makeBins_SC(AP_corr,n_bins_tot)\n",
    "id_ML,edges_ML = makeBins_SC(ML_corr,n_bins_tot)\n",
    "id_depth,edges_depth = makeBins_SC(depth_corr,n_bins_tot)\n",
    "\n",
    "id_AP = id_AP[:-2]\n",
    "id_ML = id_ML[:-2]\n",
    "id_depth = id_depth[:-2]\n",
    "\n",
    "# after creating the bins create the combinations and give to each neuron the id of the bin it is in getBinIDs\n",
    "var1,var2,var3 = id_ML,id_depth,id_AP\n",
    "groups_ML,lengths,ID_neurons_ML,bins = getBinIDs(2,var1,var2,n_bins_tot)\n",
    "groups_AP,lengths,ID_neurons_AP,bins = getBinIDs(2,var3,var2,n_bins_tot)\n",
    "\n",
    "# Helper function to compute modality matrix\n",
    "def compute_modality_fraction(modality_mask, ID_neurons, groups, total_count):\n",
    "    result = np.full((groups.shape[0], 1), np.nan)\n",
    "    for g in range(groups.shape[0]):\n",
    "        mask = ID_neurons == g\n",
    "        count = np.sum(modality_mask[mask])\n",
    "        if np.sum(mask) > 0:\n",
    "            result[g] = count / total_count\n",
    "    return result\n",
    "\n",
    "# Modality masks\n",
    "vis_mask = (modality_corr == 1).astype(int)\n",
    "aud_mask = (modality_corr == 2).astype(int)\n",
    "multi_mask = (modality_corr >= 3).astype(int)\n",
    "\n",
    "# Total counts\n",
    "tot_vis = np.sum(vis_mask)\n",
    "tot_aud = np.sum(aud_mask)\n",
    "tot_multi = np.sum(multi_mask)\n",
    "\n",
    "# Compute modality matrices\n",
    "vis_ML = compute_modality_fraction(vis_mask, ID_neurons_ML, groups_ML, tot_vis)\n",
    "vis_AP = compute_modality_fraction(vis_mask, ID_neurons_AP, groups_AP, tot_vis)\n",
    "aud_ML = compute_modality_fraction(aud_mask, ID_neurons_ML, groups_ML, tot_aud)\n",
    "aud_AP = compute_modality_fraction(aud_mask, ID_neurons_AP, groups_AP, tot_aud)\n",
    "multi_ML = compute_modality_fraction(multi_mask, ID_neurons_ML, groups_ML, tot_multi)\n",
    "multi_AP = compute_modality_fraction(multi_mask, ID_neurons_AP, groups_AP, tot_multi)\n",
    "\n",
    "# Reshape and clean up\n",
    "def reshape_for_plot(mat):\n",
    "    reshaped = np.swapaxes(mat.reshape((n_bins_tot, n_bins_tot)), 0, 1)\n",
    "    reshaped[0, :] = np.nan\n",
    "    return reshaped\n",
    "\n",
    "vis_ML = reshape_for_plot(vis_ML)\n",
    "vis_AP = reshape_for_plot(vis_AP)\n",
    "aud_ML = reshape_for_plot(aud_ML)\n",
    "aud_AP = reshape_for_plot(aud_AP)\n",
    "multi_ML = reshape_for_plot(multi_ML)\n",
    "multi_AP = reshape_for_plot(multi_AP)\n",
    "\n",
    "# and it get saved so it is easier for the plotting or just load it\n",
    "save_dir = ''.join([data_path,'neurons_datasets\\\\prop_subpopulation_subregions.npz'])\n",
    "np.savez(save_dir, vis_ML = vis_ML, vis_AP = vis_AP, aud_ML= aud_ML, aud_AP = aud_AP, multi_ML = multi_ML, multi_AP= multi_AP)\n",
    "\n",
    "AP_corr = AP_corr[:-2]\n",
    "ML_corr = ML_corr[:-2]\n",
    "depth_corr = depth_corr[:-2]\n",
    "modality_corr = modality_corr[:,0]\n",
    "animal_ID_corr = animal_ID_corr[:,0]\n",
    "experiment_ID_corr = experiment_ID_corr[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fedf7805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in a dataframe the location of each visual, auditory and multisensory neuron to then run a LMM\n",
    "# also include the animal and the recording number\n",
    "\n",
    "new_modality = modality_corr.copy()\n",
    "new_modality[new_modality >= 3] = 3\n",
    "\n",
    "# Keep only neurons with valid modality values (1, 2, 3)\n",
    "valid_mask = (new_modality >= 0) & (new_modality <= 3)\n",
    "\n",
    "# Apply mask to all your variables\n",
    "AP_valid = AP_corr[valid_mask]\n",
    "ML_valid = ML_corr[valid_mask]\n",
    "Depth_valid = depth_corr[valid_mask]\n",
    "Animal_valid = animal_ID_corr[valid_mask]\n",
    "Modality_valid = new_modality[valid_mask]\n",
    "\n",
    "# Map to strings\n",
    "modality_labels = {0: 'nr', 1: 'visual', 2: 'auditory', 3: 'multisensory'}\n",
    "modality_str = [modality_labels[m] for m in Modality_valid]\n",
    "\n",
    "df_all = pd.DataFrame({\n",
    "    'AP': AP_valid.ravel(),\n",
    "    'ML': ML_valid.ravel(),\n",
    "    'Depth': Depth_valid.ravel(),\n",
    "    'Animal': Animal_valid.ravel(),\n",
    "    'Modality': modality_str\n",
    "})\n",
    "\n",
    "\n",
    "save_dir = ''.join([data_path,'neurons_datasets\\\\df_all_modalities.csv'])\n",
    "df_all.to_csv(save_dir, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0898f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and it get saved so it is easier for the plotting or just load it\n",
    "save_dir = ''.join([data_path,'neurons_datasets\\\\AP_ML_lim.npz'])\n",
    "np.savez(save_dir, AP_lim = AP_lim, ML_lim=ML_lim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
