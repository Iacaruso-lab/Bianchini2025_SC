{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "294a0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevants paths and load functions and libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"loaded more than 1 DLL from .libs:\")\n",
    "%run Z:\\\\home\\\\shared\\\\Gaia\\\\Coliseum\\\\Delays\\\\paper_code\\\\Analysis\\\\helper_functions\\\\functions_analysis.py\n",
    "    \n",
    "data_path = 'Z:\\\\home\\\\shared\\\\Gaia\\\\Coliseum\\\\Delays\\\\paper_code\\\\Datasets\\\\movement_control_datasets\\\\'\n",
    "saving_path = 'Z:\\\\home\\\\shared\\\\Gaia\\\\Coliseum\\\\Delays\\\\paper_code\\\\Figures_output\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "823a24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of animals for this dataset\n",
    "\n",
    "file =''.join([data_path,'movement_control_animals.txt'])\n",
    "with open(file, 'r') as file:\n",
    "    loaded_folder_names = [line.strip() for line in file.readlines()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f1dee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each animal load the PRED and Test and get the decoder accuracy with 1PC\n",
    "# load the outputs from this code run_classifier_movement_control_AVdelays.py\n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_animals = these_animals.shape[0]\n",
    "n_rep = 20\n",
    "all_scores = np.zeros((n_animals,2))\n",
    "\n",
    "for count,animal in enumerate(these_animals):\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_Alldelays_Ashifted_1PC_original_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_Alldelays_Ashifted_1PC_original_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score[:11])\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,0] = np.mean(these_scores)\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_Alldelays_Ashifted_1PC_original_random_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_Alldelays_Ashifted_1PC_original_random_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score[:11])\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,1] = np.mean(these_scores)\n",
    "    \n",
    "# and it get saved so it is easier for th eplotting ot just load it\n",
    "save_dir = ''.join([data_path,'decoder_accuracy_1PC_Ashifted.npy'])\n",
    "np.save(save_dir,all_scores)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b4191b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each animal load the PRED and Test and get the decoder accuracy with 100PC\n",
    "# load the outputs from this code run_classifier_movement_control_AVdelays.py\n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_animals = these_animals.shape[0]\n",
    "n_rep = 20\n",
    "all_scores = np.zeros((n_animals,2))\n",
    "\n",
    "for count,animal in enumerate(these_animals):\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_Alldelays_Ashifted_original_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_Alldelays_Ashifted_original_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score[:11])\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,0] = np.mean(these_scores)\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_Alldelays_Ashifted_original_random_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_Alldelays_Ashifted_original_random_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score[:11])\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,1] = np.mean(these_scores)\n",
    "    \n",
    "# and it get saved so it is easier for th eplotting ot just load it\n",
    "save_dir = ''.join([data_path,'decoder_accuracy_100PC_Ashifted.npy'])\n",
    "np.save(save_dir,all_scores)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e5ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each animal load the PRED and Test and get the decoder accuracy for sound on sound off\n",
    "# load the outputs from this code \n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_animals = these_animals.shape[0]\n",
    "n_rep = 20\n",
    "all_scores = np.zeros((n_animals,2))\n",
    "\n",
    "for count,animal in enumerate(these_animals):\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_SoundNoSound_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_SoundNoSound_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,0] = np.mean(these_scores)\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_SoundNoSound_random_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_SoundNoSound_random_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,1] = np.mean(these_scores)\n",
    "    \n",
    "# and it get saved so it is easier for th eplotting ot just load it\n",
    "save_dir = ''.join([data_path,'decoder_accuracy_80dBSoundNoSound.npy'])\n",
    "np.save(save_dir,all_scores)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9c0fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each animal load the PRED and Test and get the decoder accuracy for sound on sound off AT 60dB\n",
    "# load the outputs from this code \n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_animals = these_animals.shape[0]\n",
    "n_rep = 20\n",
    "all_scores = np.zeros((n_animals,2))\n",
    "\n",
    "for count,animal in enumerate(these_animals):\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_SoundNoSound60dB_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_SoundNoSound60dB_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,0] = np.mean(these_scores)\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_SoundNoSound60dB_random_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_SoundNoSound60dB_random_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,1] = np.mean(these_scores)\n",
    "    \n",
    "# and it get saved so it is easier for th eplotting ot just load it\n",
    "save_dir = ''.join([data_path,'decoder_accuracy_60dBSoundNoSound.npy'])\n",
    "np.save(save_dir,all_scores)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1da2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each animal load the PRED and Test and get the decoder accuracy for vis stim on and off\n",
    "# load the outputs from this code \n",
    "\n",
    "n_rep = 20\n",
    "all_scores = np.zeros((n_animals,2))\n",
    "\n",
    "for count,animal in enumerate(these_animals):\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_StimNoStim_Vis_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_StimNoStim_Vis_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,0] = np.mean(these_scores)\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_StimNoStim_Vis_random_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_StimNoStim_Vis_random_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "\n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,1] = np.mean(these_scores)\n",
    "\n",
    "# and it get saved so it is easier for th eplotting ot just load it\n",
    "save_dir = ''.join([data_path,'decoder_accuracy_StimNoStim_Vis.npy'])\n",
    "np.save(save_dir,all_scores)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "754e9f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:27,  9.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract average PC1 for different sound intensities\n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_vol = 9\n",
    "avg_pc1 = np.zeros((these_animals.shape[0],n_vol))\n",
    "\n",
    "this_path = ''.join([data_path,'raw_data\\\\'])\n",
    "videoFolders = [os.path.join(this_path, d) for d in os.listdir(this_path) if os.path.isdir(os.path.join(this_path, d))]\n",
    "\n",
    "for count1,animal in tqdm(enumerate(range(these_animals.shape[0]))):\n",
    "    file=os.path.join(videoFolders[animal],'dec_data.mat')\n",
    "    data_dict = mat73.loadmat(file)\n",
    "    DAT=data_dict['dec_data']\n",
    "\n",
    "    Del_motSVD=DAT['Vol_motSVD']\n",
    "    Del_times=DAT['Vol_times']\n",
    "    Del_trials=DAT['Vol_trials']\n",
    "\n",
    "    # 10 ms resolution seem to be working well\n",
    "    num_new_times_imp = 210#420\n",
    "    resampled_motSVD = np.full((Del_motSVD.shape[0], Del_motSVD.shape[1], num_new_times_imp),np.nan)\n",
    "\n",
    "    for rep in range(Del_times.shape[0]):\n",
    "\n",
    "        these_times = Del_times[rep,:]\n",
    "        \n",
    "        # 1. Define new time grid with 10ms (0.01s) intervals\n",
    "        new_times = np.arange(np.min(these_times), np.max(these_times), 0.01)\n",
    "        num_new_times = len(new_times)\n",
    "\n",
    "        if num_new_times_imp != num_new_times:\n",
    "            print('There is a mistake!')   \n",
    "        for n in range(Del_motSVD.shape[0]):\n",
    "            interp_func = interp1d(these_times, Del_motSVD[n, rep, :], kind='linear', fill_value=\"extrapolate\")\n",
    "            resampled_motSVD[n, rep, :] = interp_func(new_times)\n",
    "            \n",
    "    sub_resampled_motSVD = resampled_motSVD[0,:,40:-60]\n",
    "    max_vol = np.mean(sub_resampled_motSVD[-50:,:],axis=0)\n",
    "    abs_max = max_vol[np.argmax(np.abs(max_vol))]\n",
    "    \n",
    "    if abs_max <0:\n",
    "        # make sure the 1st PC is always positive\n",
    "        sub_resampled_motSVD = sub_resampled_motSVD*-1   \n",
    "    \n",
    "    original_shape = sub_resampled_motSVD.shape  # (700, 110)\n",
    "\n",
    "    # 1. Reshape to 1D\n",
    "    flattened = sub_resampled_motSVD.ravel()  # or .reshape(-1)\n",
    "    # 2. Z-score normalization\n",
    "    z_scored = zscore(flattened)\n",
    "\n",
    "    # 3. Reshape back to original shape\n",
    "    z_scored_reshaped = z_scored.reshape(original_shape)\n",
    "\n",
    "    mean_sub_resampled_motSVD = np.mean(z_scored_reshaped[:,10:60],axis=1)\n",
    "\n",
    "    n_rep = 50\n",
    "    my_labels = np.repeat(np.arange(mean_sub_resampled_motSVD.shape[0]/n_rep),n_rep)\n",
    "\n",
    "    for count2,i in enumerate(np.unique(my_labels)):\n",
    "        avg_pc1[count1,count2] = np.mean(mean_sub_resampled_motSVD[my_labels==i])\n",
    "\n",
    "# and it get saved so it is easier for th eplotting ot just load it\n",
    "save_dir = ''.join([data_path,'z_scored_PC1_sound_intensity.npy'])\n",
    "np.save(save_dir,avg_pc1)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2ade67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:47, 11.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract average PC1 for different AV delays\n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_stim = 14\n",
    "avg_pc1 = np.zeros((these_animals.shape[0],n_stim))\n",
    "\n",
    "for count1,animal in tqdm(enumerate(range(9))):\n",
    "    file=os.path.join(videoFolders[animal],'dec_data.mat')\n",
    "\n",
    "    data_dict = mat73.loadmat(file)\n",
    "    DAT=data_dict['dec_data']\n",
    "\n",
    "    Del_motSVD=DAT['Del_motSVD']\n",
    "    Del_times=DAT['Del_times']\n",
    "    Del_trials=DAT['Del_trials']\n",
    "\n",
    "    # 10 ms resolution seem to be working well\n",
    "    num_new_times_imp = 210#420\n",
    "    resampled_motSVD = np.full((Del_motSVD.shape[0], Del_motSVD.shape[1], num_new_times_imp),np.nan)\n",
    "\n",
    "    for rep in range(Del_times.shape[0]):\n",
    "\n",
    "        these_times = Del_times[rep,:]\n",
    "        # 1. Define new time grid with 10ms (0.01s) intervals\n",
    "        new_times = np.arange(np.min(these_times), np.max(these_times), 0.01)\n",
    "        num_new_times = len(new_times)\n",
    "\n",
    "        if num_new_times_imp != num_new_times:\n",
    "            print('There is a mistake!')   \n",
    "        for n in range(Del_motSVD.shape[0]):\n",
    "            interp_func = interp1d(these_times, Del_motSVD[n, rep, :], kind='linear', fill_value=\"extrapolate\")\n",
    "            resampled_motSVD[n, rep, :] = interp_func(new_times) \n",
    "\n",
    "    sub_resampled_motSVD = resampled_motSVD[0,:,40:-60]\n",
    "    \n",
    "    max_vol = np.mean(sub_resampled_motSVD[600:650,:],axis=0)    \n",
    "    abs_max = max_vol[np.argmax(np.abs(max_vol))]\n",
    "    \n",
    "    if abs_max <0:\n",
    "        sub_resampled_motSVD = sub_resampled_motSVD*-1\n",
    "    \n",
    "    original_shape = sub_resampled_motSVD.shape  # (700, 110)\n",
    "\n",
    "    # 1. Reshape to 1D\n",
    "    flattened = sub_resampled_motSVD.ravel()  # or .reshape(-1)\n",
    "    # 2. Z-score normalization\n",
    "    z_scored = zscore(flattened)\n",
    "\n",
    "    # 3. Reshape back to original shape\n",
    "    z_scored_reshaped = z_scored.reshape(original_shape)\n",
    "    \n",
    "    mean_sub_resampled_motSVD = np.mean(z_scored_reshaped[:,10:80],axis=1)\n",
    "    \n",
    "    n_rep = 50\n",
    "    my_labels = np.repeat(np.arange(mean_sub_resampled_motSVD.shape[0]/n_rep),n_rep)\n",
    "\n",
    "    for count2,i in enumerate(np.unique(my_labels)):\n",
    "        avg_pc1[count1,count2] = np.mean(mean_sub_resampled_motSVD[my_labels==i])\n",
    "        \n",
    "# and it get saved so it is easier for th eplotting ot just load it\n",
    "save_dir = ''.join([data_path,'z_scored_PC1_AVdelays.npy'])\n",
    "np.save(save_dir,avg_pc1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8365b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
