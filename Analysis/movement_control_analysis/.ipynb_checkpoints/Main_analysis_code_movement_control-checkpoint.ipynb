{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294a0fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevants paths and load functions and libraries\n",
    "\n",
    "%run Z:\\\\home\\\\shared\\\\Gaia\\\\Coliseum\\\\Delays\\\\paper_code\\\\Analysis\\\\helper_functions\\\\functions_analysis.py\n",
    "\n",
    "data_path = 'paper_code\\\\Datasets\\\\movement_control_datasets\\\\' # your data path\n",
    "saving_path = 'paper_code\\\\Figures_output\\\\' # your saving figures path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "823a24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the list of animals for this dataset\n",
    "\n",
    "file =''.join([data_path,'movement_control_animals.txt'])\n",
    "with open(file, 'r') as file:\n",
    "    loaded_folder_names = [line.strip() for line in file.readlines()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e348628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading video: Z:\\home\\shared\\Gaia\\Coliseum\\Delays\\paper_code\\Datasets\\movement_control_datasets\\raw_data\\GB32_S2\\downsample_video.avi\n",
      "Video dimensions: 544x728, Total frames: 926733\n",
      "Calculating average frame and motion...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 463/463 [1:42:43<00:00, 13.31s/it]\n"
     ]
    }
   ],
   "source": [
    "# Save average frame to plot\n",
    "\n",
    "path = ''.join([data_path,'raw_data\\\\'])\n",
    "videoFolders = [os.path.join(path, d) for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "\n",
    "this_path = os.path.join(videoFolders[2])\n",
    "sub_folder = os.listdir(this_path)\n",
    "\n",
    "# Find the .avi video file in the folder\n",
    "video_files = [f for f in sub_folder if f.endswith('.avi')]\n",
    "video_path = os.path.join(this_path, video_files[0])\n",
    "\n",
    "print(f\"Loading video: {video_path}\")\n",
    "\n",
    "# Open video using cv2\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#%% Get video properties\n",
    "Ly = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "Lx = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "nframes = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"Video dimensions: {Ly}x{Lx}, Total frames: {nframes}\")\n",
    "\n",
    "# Early exit for short videos\n",
    "if nframes < 200:\n",
    "    print(\"Video is too short, skipping.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Compute avgframe and avgmotion\n",
    "nf = min(2000000, nframes)\n",
    "nt0 = min(2000, nframes)\n",
    "nsegs = int(np.floor(nf / nt0))\n",
    "tf = np.floor(np.linspace(0, nframes - nt0, nsegs)).astype(int)\n",
    "\n",
    "avgframe = np.zeros((Ly, Lx), np.float32)\n",
    "avgmotion = np.zeros((Ly, Lx), np.float32)\n",
    "ns = 0\n",
    "\n",
    "print(\"Calculating average frame and motion...\")\n",
    "\n",
    "for n in tqdm(range(nsegs)):\n",
    "    t = tf[n]\n",
    "\n",
    "    # Set the video position to the desired frame\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, t)\n",
    "    frames = []\n",
    "\n",
    "    # Read nt0 frames\n",
    "    for _ in range(nt0):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Convert to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(gray_frame)\n",
    "\n",
    "    # Stack frames into a single array (Time x Ly x Lx)\n",
    "    im = np.stack(frames, axis=0)\n",
    "\n",
    "    # Convert to float and transpose to (Ly, Lx, Time)\n",
    "    im = np.transpose(im, (1, 2, 0)).astype(np.float32)\n",
    "\n",
    "    # Add to averages\n",
    "    avgframe += im.mean(axis=-1)\n",
    "    immotion = np.abs(np.diff(im, axis=-1))\n",
    "    avgmotion += immotion.mean(axis=-1)\n",
    "    ns += 1\n",
    "\n",
    "avgframe /= float(ns)\n",
    "avgmotion /= float(ns)\n",
    "\n",
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "save_dir = ''.join([data_path,'avg_image_example.npy'])\n",
    "np.save(save_dir,avgframe) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7ab2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save psth of example experiment to plot in main figure \n",
    "\n",
    "file=os.path.join(videoFolders[2],'dec_data.mat')\n",
    "data_dict = mat73.loadmat(file)\n",
    "DAT=data_dict['dec_data']\n",
    "\n",
    "Vol_motSVD=DAT['Vol_motSVD']\n",
    "Vol_times=DAT['Vol_times']\n",
    "\n",
    "num_new_times_imp = 210\n",
    "resampled_motSVD = np.full((Vol_motSVD.shape[0], Vol_motSVD.shape[1], num_new_times_imp),np.nan)\n",
    "\n",
    "for rep in range(Vol_times.shape[0]):\n",
    "    \n",
    "    these_times = Vol_times[rep,:]\n",
    "    \n",
    "    new_times = np.arange(np.min(these_times), np.max(these_times), 0.01)\n",
    "    num_new_times = len(new_times)\n",
    "    \n",
    "    if num_new_times_imp != num_new_times:\n",
    "        print('There is a mistake!')   \n",
    "    for n in range(Vol_motSVD.shape[0]):\n",
    "        interp_func = interp1d(these_times, Vol_motSVD[n, rep, :], kind='linear', fill_value=\"extrapolate\")\n",
    "        resampled_motSVD[n, rep, :] = interp_func(new_times) \n",
    "        \n",
    "features = np.swapaxes(resampled_motSVD,0,1)\n",
    "features = features.reshape(features.shape[0],-1)\n",
    "\n",
    "# Min-Max normalization\n",
    "features_min = np.min(features)\n",
    "features_max = np.max(features)\n",
    "features_norm = 2 * (features - features_min) / (features_max - features_min) - 1\n",
    "\n",
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "save_dir = ''.join([data_path,'psth_example.npy'])\n",
    "np.save(save_dir,features_norm) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f1dee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each animal load the PRED and Test and get the decoder accuracy with 1PC\n",
    "# load the outputs from this code run_classifier_movement_control_AVdelays.py\n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_animals = these_animals.shape[0]\n",
    "n_rep = 20\n",
    "all_scores = np.zeros((n_animals,2))\n",
    "\n",
    "for count,animal in enumerate(these_animals):\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_Alldelays_Ashifted_1PC_original_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_Alldelays_Ashifted_1PC_original_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score[:11])\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,0] = np.mean(these_scores)\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_Alldelays_Ashifted_1PC_original_random_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_Alldelays_Ashifted_1PC_original_random_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score[:11])\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,1] = np.mean(these_scores)\n",
    "    \n",
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "save_dir = ''.join([data_path,'decoder_accuracy_1PC_Ashifted.npy'])\n",
    "np.save(save_dir,all_scores)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b4191b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each animal load the PRED and Test and get the decoder accuracy with 100PC\n",
    "# load the outputs from this code run_classifier_movement_control_AVdelays.py\n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_animals = these_animals.shape[0]\n",
    "n_rep = 20\n",
    "all_scores = np.zeros((n_animals,2))\n",
    "\n",
    "for count,animal in enumerate(these_animals):\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_Alldelays_Ashifted_original_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_Alldelays_Ashifted_original_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score[:11])\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,0] = np.mean(these_scores)\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_Alldelays_Ashifted_original_random_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_Alldelays_Ashifted_original_random_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score[:11])\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,1] = np.mean(these_scores)\n",
    "    \n",
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "save_dir = ''.join([data_path,'decoder_accuracy_100PC_Ashifted.npy'])\n",
    "np.save(save_dir,all_scores)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e5ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each animal load the PRED and Test and get the decoder accuracy for sound on sound off\n",
    "# load the outputs from this code \n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_animals = these_animals.shape[0]\n",
    "n_rep = 20\n",
    "all_scores = np.zeros((n_animals,2))\n",
    "\n",
    "for count,animal in enumerate(these_animals):\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_SoundNoSound_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_SoundNoSound_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,0] = np.mean(these_scores)\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_SoundNoSound_random_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_SoundNoSound_random_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,1] = np.mean(these_scores)\n",
    "    \n",
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "save_dir = ''.join([data_path,'decoder_accuracy_80dBSoundNoSound.npy'])\n",
    "np.save(save_dir,all_scores)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9c0fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each animal load the PRED and Test and get the decoder accuracy for sound on sound off AT 60dB\n",
    "# load the outputs from this code \n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_animals = these_animals.shape[0]\n",
    "n_rep = 20\n",
    "all_scores = np.zeros((n_animals,2))\n",
    "\n",
    "for count,animal in enumerate(these_animals):\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_SoundNoSound60dB_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_SoundNoSound60dB_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,0] = np.mean(these_scores)\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_SoundNoSound60dB_random_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_SoundNoSound60dB_random_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,1] = np.mean(these_scores)\n",
    "    \n",
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "save_dir = ''.join([data_path,'decoder_accuracy_60dBSoundNoSound.npy'])\n",
    "np.save(save_dir,all_scores)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1da2fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each animal load the PRED and Test and get the decoder accuracy for vis stim on and off\n",
    "# load the outputs from this code \n",
    "\n",
    "n_rep = 20\n",
    "all_scores = np.zeros((n_animals,2))\n",
    "\n",
    "for count,animal in enumerate(these_animals):\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_StimNoStim_Vis_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_StimNoStim_Vis_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "    \n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,0] = np.mean(these_scores)\n",
    "    \n",
    "    file =''.join([data_path,f'decoder_analysis\\\\PRED_StimNoStim_Vis_random_animal_{animal}_SVM.npy'])     \n",
    "    predicted=np.load(file)\n",
    "    file =''.join([data_path,f'decoder_analysis\\\\TEST_StimNoStim_Vis_random_animal_{animal}_SVM.npy'])    \n",
    "    y_test=np.load(file)\n",
    "\n",
    "    these_scores =  np.zeros((predicted.shape[0],1))\n",
    "    for rep in range(predicted.shape[0]):\n",
    "        sub_score = np.zeros((predicted.shape[1],1))\n",
    "        for k in range(predicted.shape[1]):\n",
    "            cm = confusion_matrix(y_test[rep,k,:], predicted[rep,k,:],normalize='true')*100\n",
    "            score = np.diag(cm)\n",
    "            sub_score = np.mean(score)\n",
    "    \n",
    "        # save the scores for the main figure\n",
    "        these_scores[rep] = np.mean(sub_score)\n",
    "    \n",
    "    # save the mean of this\n",
    "    all_scores[count,1] = np.mean(these_scores)\n",
    "\n",
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "save_dir = ''.join([data_path,'decoder_accuracy_StimNoStim_Vis.npy'])\n",
    "np.save(save_dir,all_scores)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "754e9f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:27,  9.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract average PC1 for different sound intensities\n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_vol = 9\n",
    "avg_pc1 = np.zeros((these_animals.shape[0],n_vol))\n",
    "\n",
    "this_path = ''.join([data_path,'raw_data\\\\'])\n",
    "videoFolders = [os.path.join(this_path, d) for d in os.listdir(this_path) if os.path.isdir(os.path.join(this_path, d))]\n",
    "\n",
    "for count1,animal in tqdm(enumerate(range(these_animals.shape[0]))):\n",
    "    file=os.path.join(videoFolders[animal],'dec_data.mat')\n",
    "    data_dict = mat73.loadmat(file)\n",
    "    DAT=data_dict['dec_data']\n",
    "\n",
    "    Del_motSVD=DAT['Vol_motSVD']\n",
    "    Del_times=DAT['Vol_times']\n",
    "    Del_trials=DAT['Vol_trials']\n",
    "\n",
    "    # 10 ms resolution seem to be working well\n",
    "    num_new_times_imp = 210#420\n",
    "    resampled_motSVD = np.full((Del_motSVD.shape[0], Del_motSVD.shape[1], num_new_times_imp),np.nan)\n",
    "\n",
    "    for rep in range(Del_times.shape[0]):\n",
    "\n",
    "        these_times = Del_times[rep,:]\n",
    "        \n",
    "        # 1. Define new time grid with 10ms (0.01s) intervals\n",
    "        new_times = np.arange(np.min(these_times), np.max(these_times), 0.01)\n",
    "        num_new_times = len(new_times)\n",
    "\n",
    "        if num_new_times_imp != num_new_times:\n",
    "            print('There is a mistake!')   \n",
    "        for n in range(Del_motSVD.shape[0]):\n",
    "            interp_func = interp1d(these_times, Del_motSVD[n, rep, :], kind='linear', fill_value=\"extrapolate\")\n",
    "            resampled_motSVD[n, rep, :] = interp_func(new_times)\n",
    "            \n",
    "    sub_resampled_motSVD = resampled_motSVD[0,:,40:-60]\n",
    "    max_vol = np.mean(sub_resampled_motSVD[-50:,:],axis=0)\n",
    "    abs_max = max_vol[np.argmax(np.abs(max_vol))]\n",
    "    \n",
    "    if abs_max <0:\n",
    "        # make sure the 1st PC is always positive\n",
    "        sub_resampled_motSVD = sub_resampled_motSVD*-1   \n",
    "    \n",
    "    original_shape = sub_resampled_motSVD.shape  # (700, 110)\n",
    "\n",
    "    # 1. Reshape to 1D\n",
    "    flattened = sub_resampled_motSVD.ravel()  # or .reshape(-1)\n",
    "    # 2. Z-score normalization\n",
    "    z_scored = zscore(flattened)\n",
    "\n",
    "    # 3. Reshape back to original shape\n",
    "    z_scored_reshaped = z_scored.reshape(original_shape)\n",
    "\n",
    "    mean_sub_resampled_motSVD = np.mean(z_scored_reshaped[:,10:60],axis=1)\n",
    "\n",
    "    n_rep = 50\n",
    "    my_labels = np.repeat(np.arange(mean_sub_resampled_motSVD.shape[0]/n_rep),n_rep)\n",
    "\n",
    "    for count2,i in enumerate(np.unique(my_labels)):\n",
    "        avg_pc1[count1,count2] = np.mean(mean_sub_resampled_motSVD[my_labels==i])\n",
    "\n",
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "save_dir = ''.join([data_path,'z_scored_PC1_sound_intensity.npy'])\n",
    "np.save(save_dir,avg_pc1)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2ade67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [01:47, 11.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract average PC1 for different AV delays\n",
    "\n",
    "these_animals = np.arange(len(loaded_folder_names))\n",
    "n_stim = 14\n",
    "avg_pc1 = np.zeros((these_animals.shape[0],n_stim))\n",
    "\n",
    "for count1,animal in tqdm(enumerate(range(9))):\n",
    "    file=os.path.join(videoFolders[animal],'dec_data.mat')\n",
    "\n",
    "    data_dict = mat73.loadmat(file)\n",
    "    DAT=data_dict['dec_data']\n",
    "\n",
    "    Del_motSVD=DAT['Del_motSVD']\n",
    "    Del_times=DAT['Del_times']\n",
    "    Del_trials=DAT['Del_trials']\n",
    "\n",
    "    # 10 ms resolution seem to be working well\n",
    "    num_new_times_imp = 210#420\n",
    "    resampled_motSVD = np.full((Del_motSVD.shape[0], Del_motSVD.shape[1], num_new_times_imp),np.nan)\n",
    "\n",
    "    for rep in range(Del_times.shape[0]):\n",
    "\n",
    "        these_times = Del_times[rep,:]\n",
    "        # 1. Define new time grid with 10ms (0.01s) intervals\n",
    "        new_times = np.arange(np.min(these_times), np.max(these_times), 0.01)\n",
    "        num_new_times = len(new_times)\n",
    "\n",
    "        if num_new_times_imp != num_new_times:\n",
    "            print('There is a mistake!')   \n",
    "        for n in range(Del_motSVD.shape[0]):\n",
    "            interp_func = interp1d(these_times, Del_motSVD[n, rep, :], kind='linear', fill_value=\"extrapolate\")\n",
    "            resampled_motSVD[n, rep, :] = interp_func(new_times) \n",
    "\n",
    "    sub_resampled_motSVD = resampled_motSVD[0,:,40:-60]\n",
    "    \n",
    "    max_vol = np.mean(sub_resampled_motSVD[600:650,:],axis=0)    \n",
    "    abs_max = max_vol[np.argmax(np.abs(max_vol))]\n",
    "    \n",
    "    if abs_max <0:\n",
    "        sub_resampled_motSVD = sub_resampled_motSVD*-1\n",
    "    \n",
    "    original_shape = sub_resampled_motSVD.shape  # (700, 110)\n",
    "\n",
    "    # 1. Reshape to 1D\n",
    "    flattened = sub_resampled_motSVD.ravel()  # or .reshape(-1)\n",
    "    # 2. Z-score normalization\n",
    "    z_scored = zscore(flattened)\n",
    "\n",
    "    # 3. Reshape back to original shape\n",
    "    z_scored_reshaped = z_scored.reshape(original_shape)\n",
    "    \n",
    "    mean_sub_resampled_motSVD = np.mean(z_scored_reshaped[:,10:80],axis=1)\n",
    "    \n",
    "    n_rep = 50\n",
    "    my_labels = np.repeat(np.arange(mean_sub_resampled_motSVD.shape[0]/n_rep),n_rep)\n",
    "\n",
    "    for count2,i in enumerate(np.unique(my_labels)):\n",
    "        avg_pc1[count1,count2] = np.mean(mean_sub_resampled_motSVD[my_labels==i])\n",
    "        \n",
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "save_dir = ''.join([data_path,'z_scored_PC1_AVdelays.npy'])\n",
    "np.save(save_dir,avg_pc1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8365b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
