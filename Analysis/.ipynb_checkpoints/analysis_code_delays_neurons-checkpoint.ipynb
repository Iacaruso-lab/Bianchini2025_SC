{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43b3e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the needed packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2804d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevants paths\n",
    "\n",
    "#data_path = '/nemo/lab/iacarusof/home/shared/Gaia/Coliseum/Delays/save_load_datasets/'\n",
    "data_path = 'Z:\\\\home\\\\shared\\\\Gaia\\\\Coliseum\\\\Delays\\\\paper_code\\\\Datasets\\\\'\n",
    "saving_path = 'Z:\\\\home\\\\shared\\\\Gaia\\\\Coliseum\\\\Delays\\\\paper_code\\\\Figures_output\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da88a5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AP_lim', 'ML_lim', 'all_boot_aud', 'all_boot_vis', 'animal_ID', 'binSize', 'coord3D', 'depth_lim', 'experiment_ID', 'modality', 'peaks', 'pvals', 'resp', 'spikes', 'trials', 'window_spikes'])\n"
     ]
    }
   ],
   "source": [
    "# import relevant datasets\n",
    "\n",
    "# load the main dataset\n",
    "file= ''.join([data_path,'neurons_datasets\\\\delay_tuning_dataset.mat'])\n",
    "data_dict = mat73.loadmat(file)\n",
    "DAT=data_dict['delay_tuning_dataset']\n",
    "\n",
    "# check keys available\n",
    "print(DAT.keys())\n",
    "\n",
    "# extract all keys\n",
    "for k in DAT.keys():\n",
    "    globals()[k] = DAT[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d033b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the onset of visual and audiotry responses - for this we use a 1ms binning\n",
    "\n",
    "file=''.join([data_path,'neurons_datasets\\\\all_spikes_1ms.mat'])\n",
    "data_dict = mat73.loadmat(file)\n",
    "DAT=data_dict['all_spikes']\n",
    "spikes_1ms = DAT['spikes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d9a010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the onset of visual and audiotry responses\n",
    "# 1 - Define the standard deviation for the Gaussian filter\n",
    "sigma = 1.5\n",
    "\n",
    "# Apply the Gaussian filter along the third axis\n",
    "spikes_smooth = gaussian_filter1d(spikes_1ms, sigma, axis=2) #axis 2 is time\n",
    "\n",
    "# Reshape the array to facilitate mean calculation\n",
    "reshaped_array= spikes_smooth.reshape(spikes_smooth.shape[0], -1, 50, spikes_smooth.shape[2])\n",
    "\n",
    "# Compute the mean along the second axis\n",
    "mean_array = np.mean(reshaped_array, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0334e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- extract peak time FR for vis and aud trials\n",
    "spikes_1ms.shape #window=[-1 1];\n",
    "latencies = np.zeros((spikes_smooth.shape[0],3))\n",
    "start_window = 5#ms\n",
    "start_window += 33#ms\n",
    "cut_array = mean_array[:,:,start_window:]\n",
    "\n",
    "for i in range(spikes_smooth.shape[0]): #for each neuron\n",
    "    latencies[i,0] = np.argmax(cut_array[i,-2,5:]) #vis latency\n",
    "    latencies[i,1] =  np.argmax(cut_array[i,-1,5:]) #aud latency\n",
    "    latencies[i,2] =  np.argmax(cut_array[i,0,5:]) #multi 0 latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e03327a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the latencies for them to be easier to load for figure plotting\n",
    "\n",
    "save_dir = ''.join([data_path,'neurons_datasets\\\\latencies_vis_aud.npy'])\n",
    "np.save(save_dir,latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac94f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate inter trial variaility for delay neurons\n",
    "\n",
    "# get the delay neurons\n",
    "peaks = np.squeeze(peaks)\n",
    "\n",
    "sig_del = []\n",
    "for i in range(peaks.shape[0]):\n",
    "    y = peaks[i,:-2]\n",
    "\n",
    "    vis_FR = peaks[i,-2]\n",
    "    aud_FR = peaks[i,-1]\n",
    "\n",
    "    if vis_FR>aud_FR:\n",
    "        boot_out = all_boot_vis[i,:]\n",
    "    elif aud_FR>vis_FR:\n",
    "        boot_out = all_boot_aud[i,:]\n",
    "    \n",
    "    pos_sig = np.argwhere(boot_out>0)\n",
    "\n",
    "    if len(pos_sig)>0:\n",
    "        sig_del.append(i)\n",
    "\n",
    "sig_del = np.array(sig_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb464914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this we use 10ms binning\n",
    "\n",
    "reshaped_array= spikes.reshape(spikes.shape[0], -1, 50, spikes.shape[2])\n",
    "reshaped_array = reshaped_array[:,:,:,98:98+25] # from -20ms to 250ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "933017af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 1/5360 [00:36<53:43:25, 36.09s/it]C:\\Users\\bianchg\\Miniconda3\\envs\\master\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4427: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "  4%|███▎                                                                         | 227/5360 [05:26<2:03:07,  1.44s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\2\\ipykernel_15488\\3804042355.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[1;31m# Compute Pearson correlation coefficient between repeats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0mcorrelation_coefficients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_neuron_spikes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthis_neuron_spikes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Loop through each trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\master\\lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36mpearsonr\u001b[1;34m(x, y, alternative)\u001b[0m\n\u001b[0;32m   4447\u001b[0m     \u001b[1;31m# use at least 64 bit floating point.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4448\u001b[0m     \u001b[0mxm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mxmean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4449\u001b[1;33m     \u001b[0mym\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mymean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4451\u001b[0m     \u001b[1;31m# Unlike np.linalg.norm or the expression sqrt((xm*xm).sum()),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get the shape of the reshaped array\n",
    "n_neurons, trials, reps, time_points = reshaped_array.shape\n",
    "\n",
    "# Initialize the final correlation array\n",
    "final_corr = np.zeros((n_neurons, trials))\n",
    "\n",
    "# Loop over neurons\n",
    "for n in tqdm(range(n_neurons)):\n",
    "    this_neuron_spikes = reshaped_array[n]\n",
    "\n",
    "    # Initialize an array to store correlation coefficients for each trial\n",
    "    correlation_coefficients = np.zeros((trials, reps, reps))\n",
    "\n",
    "    # Compute correlation coefficients for each trial\n",
    "    for trial in range(trials):\n",
    "        for i in range(reps):\n",
    "            for j in range(reps):\n",
    "                # Compute Pearson correlation coefficient between repeats\n",
    "                correlation_coefficients[trial, i, j],pval = pearsonr(this_neuron_spikes[trial, i], this_neuron_spikes[trial, j])\n",
    "\n",
    "    # Loop through each trial\n",
    "    for trial in range(trials):\n",
    "        # Extract the lower triangle of the correlation matrix\n",
    "        lower_triangle = np.tril(correlation_coefficients[trial,:,:])\n",
    "\n",
    "        # Exclude the main diagonal (i.e., correlation of a repeat with itself)\n",
    "        lower_triangle = lower_triangle[lower_triangle != 0]\n",
    "\n",
    "        # Calculate the average correlation coefficient for the trial\n",
    "        final_corr[n,trial] = np.nanmean(lower_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa089d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and it get saved so it is easier for the plotting ot just load it\n",
    "\n",
    "save_dir = ''.join([data_path,'neurons_datasets\\\\Inter_trial_variability_neurons.npy'])\n",
    "np.save(save_dir,final_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the chance reliability gets also calculated bu for the whole spike trains (larger window of time)\n",
    "\n",
    "file=''.join([data_path,'neurons_datasets\\\\all_spikes_large_window.mat'])\n",
    "data_dict = mat73.loadmat(file)\n",
    "DAT=data_dict['all_spikes']\n",
    "spikes_1ms = DAT['spikes']\n",
    "\n",
    "# for all possible times of 250ms length - to match the previous one\n",
    "reshaped_array2= spikes_10ms.reshape(spikes_10ms.shape[0], spikes_10ms.shape[1], 25,-1)\n",
    "reshaped_array2 = reshaped_array2.swapaxes(3,2)\n",
    "reshaped_array2 = reshaped_array2.reshape(reshaped_array2.shape[0],-1,reshaped_array2.shape[3])\n",
    "print(reshaped_array2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5297a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of the reshaped array\n",
    "n_neurons, trials, reps, time_points = reshaped_array.shape\n",
    "\n",
    "# Initialize the final correlation array\n",
    "final_corr = np.zeros((n_neurons, trials))\n",
    "\n",
    "# Loop over neurons\n",
    "for n in tqdm(range(n_neurons)):\n",
    "    this_neuron_spikes = reshaped_array[n]\n",
    "\n",
    "    # Initialize an array to store correlation coefficients for each trial\n",
    "    correlation_coefficients = np.zeros((trials, reps, reps))\n",
    "\n",
    "    # Compute correlation coefficients for each trial\n",
    "    for trial in range(trials):\n",
    "        for i in range(reps):\n",
    "            for j in range(reps):\n",
    "                # Compute Pearson correlation coefficient between repeats\n",
    "                correlation_coefficients[trial, i, j],pval = pearsonr(this_neuron_spikes[trial, i], this_neuron_spikes[trial, j])\n",
    "\n",
    "    # Loop through each trial\n",
    "    for trial in range(trials):\n",
    "        # Extract the lower triangle of the correlation matrix\n",
    "        lower_triangle = np.tril(correlation_coefficients[trial,:,:])\n",
    "\n",
    "        # Exclude the main diagonal (i.e., correlation of a repeat with itself)\n",
    "        lower_triangle = lower_triangle[lower_triangle != 0]\n",
    "\n",
    "        # Calculate the average correlation coefficient for the trial\n",
    "        final_corr[n,trial] = np.nanmean(lower_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5330d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and it get saved so it is easier for th eplotting ot just load it\n",
    "\n",
    "save_dir = ''.join([data_path,'neurons_datasets\\\\Inter_trial_variability_neurons_random.npy'])\n",
    "np.save(save_dir,final_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0626f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f342a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
