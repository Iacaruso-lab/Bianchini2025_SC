{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d853b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevants paths and load functions and libraries\n",
    "\n",
    "%run Bianchini2025_SC\\\\Analysis\\\\helper_functions\\\\functions_analysis.py\n",
    "    \n",
    "data_path = 'Bianchini2025_SC\\\\Datasets\\\\' # your data path\n",
    "saving_path = 'Bianchini2025_SC\\\\Figures_output\\\\' # your saving figures path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7299a226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['corrected_CCG', 'pair_3D_dist', 'pair_distance_depth', 'pair_ids', 'pair_meanAP_pos', 'pair_meanML_pos', 'pair_meandepth_pos', 'pair_modality', 'pair_positions_depth', 'peak_lag', 'peaks', 'post_id', 'post_mean_FR', 'post_modality', 'post_pair_positions_3D', 'pre_id', 'pre_mean_FR', 'pre_modality', 'pre_pair_positions_3D', 'sess_n', 'sig_idx_4sd', 'sig_idx_5sd', 'sig_idx_6sd', 'sig_idx_7sd', 'trough_lag', 'troughs'])\n"
     ]
    }
   ],
   "source": [
    "# load the CCG dataset\n",
    "\n",
    "file = ''.join([data_path,'connectivity_dataset\\\\CCG_dataset_baseline_RF_mapping.mat'])\n",
    "CCG_dict = mat73.loadmat(file)\n",
    "all_ccg = CCG_dict['all_ccg']\n",
    "\n",
    "for k in all_ccg.keys():\n",
    "    globals()[k] = all_ccg[k]\n",
    "    \n",
    "connection_strength = np.copy(peaks)\n",
    "#check keys available\n",
    "print(all_ccg.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22eb0e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AUD', 'AUD_coords', 'AUD_fits_interp', 'AUD_peaks', 'AUD_r', 'AV', 'MULTI', 'MULTI_coords', 'MULTI_fits_interp', 'MULTI_peaks', 'VIS', 'VIS_coords', 'VIS_fits_interp', 'VIS_peaks', 'VIS_r', 'animal_ID', 'coord3D', 'experiment_ID', 'locs', 'n_col', 'n_rows', 'neuron_ID', 'slices_degrees', 'stims'])\n"
     ]
    }
   ],
   "source": [
    "# Plot second section of Figure 1 - RF mapping\n",
    "# this uses a second dataset that needs to be loaded \n",
    "\n",
    "# load dataset\n",
    "file=''.join([data_path,'neurons_datasets\\\\retinotopy_dataset.mat'])\n",
    "data_dict = mat73.loadmat(file)\n",
    "DAT=data_dict['retinotopy_dataset']\n",
    "\n",
    "#check keys available\n",
    "print(DAT.keys())\n",
    "\n",
    "#I want to extract all keys in DAT and have them as arrays\n",
    "for k in DAT.keys():\n",
    "    globals()[k] = DAT[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c9881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the modality of the neurons accordingly \n",
    "modality = ((AUD | VIS | AV)).astype(int)\n",
    "\n",
    "vis_pos = np.argwhere(VIS>0)[:,0]\n",
    "aud_pos = np.argwhere(AUD>0)[:,0]\n",
    "audvis_pos = np.argwhere(AV>0)[:,0]\n",
    "\n",
    "new_modality = np.zeros((modality.shape[0],1))\n",
    "new_modality[vis_pos] = 1\n",
    "new_modality[aud_pos] = 2\n",
    "new_modality[audvis_pos] = 3\n",
    "\n",
    "indices = pre_id.astype(int) - 1\n",
    "# Use modality as a lookup table\n",
    "pre_modality = new_modality[indices][:,0]\n",
    "\n",
    "indices = post_id.astype(int) - 1\n",
    "# Use modality as a lookup table\n",
    "post_modality = new_modality[indices][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3d7034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate and plot the correlation probability for both pairs and stim pairs\n",
    "def calculate_probability(pair_distance, over_tot, sig_indices, bin_width = 50, lag_sign=None):\n",
    "\n",
    "    min_val = np.nanmin(pair_distance)\n",
    "    max_val = np.nanmax(pair_distance)\n",
    "    n_bins = int(np.round((max_val - min_val) / bin_width))\n",
    "\n",
    "    idA, edges = makeBins_SC(pair_distance, n_bins)\n",
    "\n",
    "    idB = idA[over_tot]\n",
    "    if lag_sign is not None:\n",
    "        sig_lag_sign = lag_sign[sig_indices]\n",
    "        pairs_connected = sig_indices[sig_lag_sign != 0]\n",
    "        idC = idA[pairs_connected]\n",
    "    else:\n",
    "        idC = idA[sig_indices]\n",
    "\n",
    "    perc = []\n",
    "    for b in range(1, n_bins + 1):\n",
    "        tot = idB[idB == b].shape[0]\n",
    "        sig = idC[idC == b].shape[0]\n",
    "        if tot == 0:\n",
    "            perc.append(float('nan'))\n",
    "        elif sig == 0:\n",
    "            perc.append(0)\n",
    "        else:\n",
    "            perc.append((sig / tot) * 100)\n",
    "\n",
    "    return edges, perc, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4036623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess probability of correlation and connection\n",
    "\n",
    "min_FR = 10#10 #Hz\n",
    "sig_idx = sig_idx_5sd # peak a SD\n",
    "\n",
    "# Significant pair indices based on statistical significance + modality\n",
    "sig_indices = np.where(\n",
    "    (sig_idx == 1) &\n",
    "    (pre_modality >= 1) &\n",
    "    (post_modality >= 1)\n",
    ")[0]\n",
    "\n",
    "# Total pair indices that pass basic modality threshold\n",
    "over_tot = np.where(\n",
    "    (pre_modality > 0) &\n",
    "    (post_modality > 0)\n",
    ")[0]\n",
    "\n",
    "\n",
    "# Every pair is one row: keep as-is, no [::2]\n",
    "sig_pairs = sig_indices\n",
    "tot_pairs = over_tot\n",
    "\n",
    "# Define directionality\n",
    "lag_sign = np.zeros(peak_lag.shape[0])\n",
    "lag_sign[peak_lag >= 10] = 1\n",
    "lag_sign[peak_lag <= -10] = -1\n",
    "\n",
    "# Direction of only significant pairs\n",
    "sig_lag_sign = lag_sign[sig_indices]\n",
    "pairs_connected = sig_indices[sig_lag_sign != 0]\n",
    "pairs_simultanous = sig_indices[sig_lag_sign == 0]\n",
    "\n",
    "# Connection flag for all pairs\n",
    "is_connected = np.zeros(pair_ids.shape[0], dtype=bool)\n",
    "is_connected[pairs_connected] = True # lag >1ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4a2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation matrix for multisensory RF\n",
    "\n",
    "all_norm_data = np.zeros((MULTI_peaks.shape[0],MULTI_peaks.shape[1]))\n",
    "\n",
    "for n in range(MULTI_peaks.shape[0]):\n",
    "    RF = MULTI_peaks[n,:]\n",
    "    norm_data = (RF - np.nanmin(RF)) / (np.nanmax(RF) - np.nanmin(RF))\n",
    "    \n",
    "    all_norm_data[n,:] = norm_data\n",
    "    \n",
    "corr_matrix_av = np.corrcoef(all_norm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a242609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-based indices for significant pairs\n",
    "ids_sig_pairs = (pair_ids[pairs_connected, :] - 1).astype(int)\n",
    "correlation_values_sign = corr_matrix_av[ids_sig_pairs[:, 0], ids_sig_pairs[:, 1]]\n",
    "sess_for_sig_pairs = sess_n[pairs_connected]  # sessions for significant pairs (using first neuron)\n",
    "\n",
    "non_sig_pairs = np.setdiff1d(tot_pairs, pairs_connected)\n",
    "ids_non_sig_pairs = (pair_ids[non_sig_pairs, :] - 1).astype(int)\n",
    "correlation_values_non_sign = corr_matrix_av[ids_non_sig_pairs[:, 0], ids_non_sig_pairs[:, 1]]\n",
    "sess_for_non_sig_pairs = sess_n[non_sig_pairs]  # sessions for non-significant pairs\n",
    "\n",
    "# Dictionaries to hold correlations by session\n",
    "sig_corrs_by_session = {}\n",
    "non_sig_corrs_by_session = {}\n",
    "\n",
    "# Unique sessions present in either sig or non-sig pairs\n",
    "unique_sessions = np.unique(np.concatenate([sess_for_sig_pairs, sess_for_non_sig_pairs]))\n",
    "\n",
    "for sess in unique_sessions:\n",
    "    # Significant correlations for this session\n",
    "    mask_sig = sess_for_sig_pairs == sess\n",
    "    sig_corrs_by_session[sess] = correlation_values_sign[mask_sig]\n",
    "\n",
    "    # Non-significant correlations for this session\n",
    "    mask_non_sig = sess_for_non_sig_pairs == sess\n",
    "    non_sig_corrs_by_session[sess] = correlation_values_non_sign[mask_non_sig]\n",
    "    \n",
    "# Combine correlation values\n",
    "all_sig_corrs = np.concatenate([np.array(v).flatten() for v in sig_corrs_by_session.values()])\n",
    "all_non_sig_corrs = np.concatenate([np.array(v).flatten() for v in non_sig_corrs_by_session.values()])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"correlation\": np.concatenate([all_sig_corrs, all_non_sig_corrs]),\n",
    "    \"significance\": [\"significant\"] * len(all_sig_corrs) + [\"non-significant\"] * len(all_non_sig_corrs)\n",
    "})\n",
    "\n",
    "# save it to be plotted\n",
    "save_dir = ''.join([data_path,'connectivity_dataset\\\\RF_correlation_connected_vs_notconnected.csv'])\n",
    "df.to_csv(save_dir,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8baacef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sessionwise_shuffled_conn_prob(\n",
    "    sess_n, is_connected, pair_corrs, bins, n_boot=1000\n",
    "):\n",
    "    n_bins = len(bins) - 1\n",
    "\n",
    "    # Mapping: session â†’ list of indices\n",
    "    session_to_indices = defaultdict(list)\n",
    "    for i, s in enumerate(sess_n):\n",
    "        session_to_indices[s].append(i)\n",
    "\n",
    "    # Observed connection probabilities\n",
    "    conn_prob_obs = []\n",
    "    n_total = []\n",
    "    n_connected = []\n",
    "    for i in range(n_bins):\n",
    "        if i == 0:\n",
    "            in_bin = pair_corrs <= bins[i + 1]\n",
    "        elif i == n_bins - 1:\n",
    "            in_bin = pair_corrs >= bins[i]\n",
    "        else:\n",
    "            in_bin = (pair_corrs >= bins[i]) & (pair_corrs < bins[i + 1])\n",
    "\n",
    "        total = np.sum(in_bin)\n",
    "        connected = np.sum(is_connected[in_bin])\n",
    "        n_total.append(total)\n",
    "        n_connected.append(connected)\n",
    "        conn_prob_obs.append((connected / total) * 100 if total > 0 else np.nan)\n",
    "    conn_prob_obs = np.array(conn_prob_obs)\n",
    "\n",
    "    # Null distribution: shuffle correlations only within each session\n",
    "    conn_prob_null = np.empty((n_boot, n_bins))\n",
    "\n",
    "    for b in range(n_boot):\n",
    "        shuffled_corrs = np.copy(pair_corrs)\n",
    "\n",
    "        for s, indices in session_to_indices.items():\n",
    "            idx = np.array(indices)\n",
    "            if len(idx) > 1:\n",
    "                shuffled_corrs[idx] = np.random.permutation(pair_corrs[idx])\n",
    "\n",
    "        for i in range(n_bins):\n",
    "            if i == 0:\n",
    "                in_bin = shuffled_corrs <= bins[i + 1]\n",
    "            elif i == n_bins - 1:\n",
    "                in_bin = shuffled_corrs >= bins[i]\n",
    "            else:\n",
    "                in_bin = (shuffled_corrs >= bins[i]) & (shuffled_corrs < bins[i + 1])\n",
    "\n",
    "            total = np.sum(in_bin)\n",
    "            connected = np.sum(is_connected[in_bin])\n",
    "            conn_prob_null[b, i] = (connected / total) * 100 if total > 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"conn_prob_obs\": conn_prob_obs,\n",
    "        \"conn_prob_null\": conn_prob_null,\n",
    "        \"n_total\": n_total,\n",
    "        \"n_connected\": n_connected,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1ecc9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack correlations\n",
    "\n",
    "exp_to_animal = {}\n",
    "for exp, animal in zip(experiment_ID, animal_ID):\n",
    "    exp_to_animal[exp] = animal\n",
    "sess_n_int = sess_n.astype(int)\n",
    "animal_n = np.array([exp_to_animal[exp] for exp in sess_n_int])\n",
    "\n",
    "pair_corrs = np.concatenate([correlation_values_sign, correlation_values_non_sign])\n",
    "is_connected = np.concatenate([np.ones_like(correlation_values_sign, dtype=bool),\n",
    "                               np.zeros_like(correlation_values_non_sign, dtype=bool)])\n",
    "sess_n = np.concatenate([sess_for_sig_pairs, sess_for_non_sig_pairs])\n",
    "\n",
    "bins = np.arange(-0.1, 0.9, 0.1)\n",
    "\n",
    "results = sessionwise_shuffled_conn_prob(\n",
    "    sess_n=sess_n,\n",
    "    is_connected=is_connected,\n",
    "    pair_corrs=pair_corrs,\n",
    "    bins=bins,\n",
    "    n_boot=1000  # or however many bootstraps you want\n",
    ")\n",
    "\n",
    "# save it to be plotted\n",
    "results[\"n_pairs_connected\"] = pairs_connected.shape[0]\n",
    "results[\"n_pairs_total\"] = tot_pairs.shape[0]\n",
    "results[\"bins\"] = bins\n",
    "save_path = data_path + 'connectivity_dataset\\\\RF_correlation_as_function_connectivity.npz'\n",
    "np.savez(save_path, **results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "89dab246",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_counts = np.array(n_connected)\n",
    "total_counts = np.array(n_total)\n",
    "not_connected = total_counts - connected_counts\n",
    "\n",
    "counts_matrix = np.column_stack((connected_counts, total_counts - connected_counts))\n",
    "\n",
    "# conn_prob_null: shape (n_boot, n_bins)\n",
    "# Make sure it's a NumPy array\n",
    "conn_prob_null = np.asarray(conn_prob_null)\n",
    "\n",
    "# Save to .mat file\n",
    "scipy.io.savemat(''.join([data_path,'connectivity_dataset\\\\RF_connectivity_cochran_data.mat']), {\n",
    "    'counts_matrix': counts_matrix,\n",
    "    'conn_prob_null': conn_prob_null\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
